{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66a56637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "448ea816",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a68da8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x000001FAC04F47C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001FAC04F46D0>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382de7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Srimad. Being a B Tech student can be a challenging yet rewarding experience. Which branch of engineering are you studying? Are you in your first year or have you progressed to a higher semester?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 47, 'total_tokens': 93, 'completion_time': 0.108009127, 'completion_tokens_details': None, 'prompt_time': 0.002687229, 'prompt_tokens_details': None, 'queue_time': 0.046407937, 'total_time': 0.110696356}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2904-172f-7711-9446-f5fae5a6b8a8-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 47, 'output_tokens': 46, 'total_tokens': 93})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content = \" my name is srimad , i am in btech\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d61a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Srimad, and you're a B Tech student.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 111, 'total_tokens': 127, 'completion_time': 0.025415731, 'completion_tokens_details': None, 'prompt_time': 0.00633597, 'prompt_tokens_details': None, 'queue_time': 0.045747579, 'total_time': 0.031751701}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c2908-ca59-7573-b210-6dcba9686299-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 111, 'output_tokens': 16, 'total_tokens': 127})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "[\n",
    "    HumanMessage(content= \"my name is srimad , i am in btech\"),\n",
    "    AIMessage(content=\"Nice to meet you, Srimad. Being a B Tech student can be a challenging yet rewarding experience. Which branch of engineering are you studying? Are you in your first year or have you progressed to a higher semester? \"),\n",
    "    HumanMessage(content = \"hey whats my name what do i do\")\n",
    "]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "862941ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##message history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id=str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = BaseChatMessageHistory()\n",
    "\n",
    "    return store[session_id] \n",
    "\n",
    "with_message_history= RunnableWithMessageHistory(model,get_session_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d53654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e9ddb8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class BaseChatMessageHistory with abstract method clear",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response  \u001b[38;5;241m=\u001b[39m \u001b[43mwith_message_history\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmy name is srimad, i am in btech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Python\\GEN AI\\Chatbot with langchain\\venv2\\lib\\site-packages\\langchain_core\\runnables\\base.py:5693\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5684\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5686\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5689\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5690\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m   5691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5692\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m-> 5693\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   5694\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5695\u001b[0m     )\n",
      "File \u001b[1;32md:\\Python\\GEN AI\\Chatbot with langchain\\venv2\\lib\\site-packages\\langchain_core\\runnables\\history.py:596\u001b[0m, in \u001b[0;36mRunnableWithMessageHistory._merge_configs\u001b[1;34m(self, *configs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(expected_keys) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parameter_names:\n\u001b[0;32m    595\u001b[0m         \u001b[38;5;66;03m# If arity = 1, then invoke function by positional arguments\u001b[39;00m\n\u001b[1;32m--> 596\u001b[0m         message_history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_session_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    600\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config:\n",
      "Cell \u001b[1;32mIn[22], line 9\u001b[0m, in \u001b[0;36mget_session_history\u001b[1;34m(session_id)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_session_history\u001b[39m(session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mBaseChatMessageHistory:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m session_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m store:\n\u001b[1;32m----> 9\u001b[0m         store[session_id] \u001b[38;5;241m=\u001b[39m \u001b[43mBaseChatMessageHistory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m store[session_id]\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't instantiate abstract class BaseChatMessageHistory with abstract method clear"
     ]
    }
   ],
   "source": [
    "response  = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"my name is srimad, i am in btech\")],\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46e11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
